{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07027f43-2e7a-47eb-8e34-1661866c7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Theory Questions ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcab48-2bc2-44a1-9e02-c24699821216",
   "metadata": {},
   "source": [
    "1.\tWhat is Logistic Regression, and how does it differ from Linear Regression?\n",
    ">> Logistic regression is a statistical method used for binary classification tasks, predicting the probability of a binary outcome (0 or 1). It differs from linear regression in that linear regression is used for predicting continuous variables, while logistic regression models the probability of a categorical outcome using the Sigmoid function.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "2.\tWhat is the mathematical equation of Logistic Regression?\n",
    ">> The equation for logistic regression is:\n",
    "P(y=1∣X)=11+e−(β0+β1x1+⋯+βnxn)P(y = 1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n)}}P(y=1∣X)=1+e−(β0+β1x1+⋯+βnxn)1 \n",
    "Where:\n",
    "P(y=1∣X)P(y = 1 | X)P(y=1∣X) is the probability of the outcome being 1 given the input features XXX,\n",
    "β0\\beta_0β0 is the intercept term,\n",
    "β1,…,βn\\beta_1, \\dots, \\beta_nβ1,…,βn are the coefficients for the features x1,…,xnx_1, \\dots, x_nx1,…,xn.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "3.\tWhy do we use the Sigmoid function in Logistic Regression?\n",
    ">> The Sigmoid function is used in logistic regression to map predicted values to probabilities. It converts any real-valued number into a value between 0 and 1, which can be interpreted as the probability of the positive class in binary classification.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "4.\tWhat is the cost function of Logistic Regression?\n",
    ">> The cost function for logistic regression is the Log-Loss or Binary Cross-Entropy function:\n",
    "J(θ)=−1m∑i=1m[yilog⁡(hθ(xi))+(1−yi)log⁡(1−hθ(xi))]J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right]J(θ)=−m1i=1∑m[yilog(hθ(xi))+(1−yi)log(1−hθ(xi))] \n",
    "Where:\n",
    "mmm is the number of training examples,\n",
    "yiy_iyi is the actual label,\n",
    "hθ(xi)h_\\theta(x_i)hθ(xi) is the predicted probability.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "5.\tWhat is Regularization in Logistic Regression? Why is it needed?\n",
    "Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function. It helps in controlling the complexity of the model by limiting the magnitude of the coefficients. Common regularization techniques include L1 (Lasso), L2 (Ridge), and Elastic Net.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "6.Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
    "•\tLasso (L1 Regularization): Adds a penalty proportional to the absolute values of the coefficients, leading to sparse models (some coefficients may become zero).\n",
    "•\tRidge (L2 Regularization): Adds a penalty proportional to the square of the coefficients, which helps to shrink the coefficients but does not make them exactly zero.\n",
    "•\tElastic Net: Combines both L1 and L2 regularization, providing a balance between the benefits of Lasso and Ridge.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "7.\tWhen should we use Elastic Net instead of Lasso or Ridge?\n",
    "Elastic Net is used when there is a large number of features, and you suspect that some of them may be highly correlated. It provides better generalization when neither Lasso nor Ridge is sufficient on its own.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "8.\tWhat is the impact of the regularization parameter (λ) in Logistic Regression?\n",
    "The regularization parameter λ\\lambdaλ controls the strength of the penalty applied to the coefficients. A higher λ\\lambdaλ results in stronger regularization, leading to smaller coefficient values and potentially simpler models. A lower λ\\lambdaλ allows the model to fit the data more closely, but it may risk overfitting.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "9.\tWhat are the key assumptions of Logistic Regression?\n",
    "The key assumptions are:\n",
    "The dependent variable is binary (0 or 1).\n",
    "The relationship between the predictors and the log-odds is linear.\n",
    "The observations are independent of each other.\n",
    "There is little to no multicollinearity among the independent variables.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "10.\tWhat are some alternatives to Logistic Regression for classification tasks?\n",
    "Alternatives to logistic regression include:\n",
    "•\tDecision Trees:\n",
    "Decision trees split data into decision nodes based on features, making them easy to understand. However, they can overfit and be unstable with noisy data. They're great for simple datasets but may need pruning to generalize better.\n",
    "•\tRandom Forests:\n",
    "Random forests use multiple decision trees to reduce overfitting and increase robustness. They're more accurate than single decision trees but less interpretable and computationally expensive.\n",
    "•\tSupport Vector Machines (SVM):\n",
    "SVM finds a hyperplane that separates classes in high-dimensional spaces. It's effective for clear class separation but can be slow and require careful tuning for large datasets.\n",
    "•\tK-Nearest Neighbors (KNN):\n",
    "KNN classifies based on the nearest neighbors of a data point. It’s simple and works well for small datasets but becomes slow with larger ones and is sensitive to irrelevant features.\n",
    "•\tNeural Networks:\n",
    "Neural networks learn complex patterns through layers of nodes, making them powerful for large, complex data. They require large datasets and significant computational power, but are less interpretable than simpler models.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "11.\tWhat are Classification Evaluation Metrics?\n",
    "•  Accuracy: Proportion of correct predictions out of all predictions. Can be misleading in imbalanced datasets.\n",
    "•  Precision: Proportion of true positives out of predicted positives. High precision means fewer false positives.\n",
    "•  Recall: Proportion of actual positives correctly predicted. High recall means fewer false negatives.\n",
    "•  F1-Score: Harmonic mean of precision and recall, balancing both metrics.\n",
    "•  ROC-AUC: Measures the trade-off between true positive and false positive rates. Higher AUC indicates better performance.\n",
    "•  Confusion Matrix: A table showing true positives, true negatives, false positives, and false negatives, helping identify model errors.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "12.\tHow does class imbalance affect Logistic Regression?\n",
    "Class imbalance can lead to biased predictions, where the model is biased toward the majority class. This results in poor predictive performance for the minority class. Techniques like class weighting or resampling (over-sampling/under-sampling) can help mitigate this issue.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "13.\tWhat is Hyperparameter Tuning in Logistic Regression?\n",
    "Hyperparameter tuning involves selecting the best hyperparameters (such as regularization strength λ\\lambdaλ, solver type, and others) to optimize the model’s performance. Grid Search and Random Search are commonly used methods for hyperparameter tuning.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "14.\tWhat are different solvers in Logistic Regression? Which one should be used?\n",
    "•\tCommon solvers include:\n",
    "o\t'liblinear': Suitable for small datasets and when regularization is used.\n",
    "o\t'saga': Handles large datasets and supports Elastic Net regularization.\n",
    "o\t'newton-cg' and 'lbfgs': Good for multinomial logistic regression (when there are multiple classes).\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "15.\tHow is Logistic Regression extended for multiclass classification?\n",
    "Logistic regression can be extended for multiclass classification using techniques like One-vs-Rest (OvR) or Softmax regression. In OvR, multiple binary classifiers are trained, one for each class, while Softmax applies a probability distribution to all classes.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "16.\tWhat are the advantages and disadvantages of Logistic Regression?\n",
    "o\tAdvantages:\n",
    ">> \tSimple and interpretable.\n",
    ">> Works well with linearly separable data.\n",
    ">> Efficient for binary classification tasks.\n",
    "o\tDisadvantages:\n",
    ">> Assumes a linear relationship between features and log-odds.\n",
    ">> Prone to underperforming with non-linear decision boundaries or complex data.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "17.\tWhat are some use cases of Logistic Regression?\n",
    ">> Logistic regression is commonly used in:\n",
    ">> Binary classification (e.g., spam detection, medical diagnosis).\n",
    ">> Credit scoring.\n",
    ">> Predicting the likelihood of events (e.g., churn prediction).\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "18.\tWhat is the difference between Softmax Regression and Logistic Regression?\n",
    "Logistic regression is used for binary classification, while Softmax regression (also called multinomial logistic regression) is an extension of logistic regression used for multi-class classification, where the outcome can belong to one of three or more classes.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "19.\tHow do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
    "One-vs-Rest is useful when the number of classes is large or when the classes are not mutually exclusive. Softmax is typically preferred when the classes are mutually exclusive and when there is a need to model the probability distribution over multiple classes.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "20.\tHow do we interpret coefficients in Logistic Regression?\n",
    "The coefficients in logistic regression represent the log-odds change in the outcome for a one-unit increase in the respective feature. The larger the coefficient, the stronger the influence of the feature on the prediction. Coefficients can be exponentiated to interpret them as odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157b1db-f4d3-4faf-b6c6-4c4a2a93797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Practical Questions ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ba06f-aef9-4d4e-ab15-e417c14b9a6c",
   "metadata": {},
   "source": [
    "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf28e52-aba8-42de-9fe4-f9b86ae14559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f647df3-3507-4ec2-94f7-c181aa54da4f",
   "metadata": {},
   "source": [
    "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5ed865-fe4f-44b7-8ff8-1ec8a6303065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularization (Lasso) Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with L1 Regularization (Lasso)\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "model_l1.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_l1 = model_l1.predict(X_test)\n",
    "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "print(f\"L1 Regularization (Lasso) Model Accuracy: {accuracy_l1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a5cf8-cdf3-4465-a099-c3efab94ecc0",
   "metadata": {},
   "source": [
    "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd631136-0976-489e-b7c4-f8a1de394f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularization (Ridge) Model Accuracy: 0.9737\n",
      "Model Coefficients: [[-0.40865789 -0.3880742  -0.37216057 -0.47593186 -0.05621001  0.55288093\n",
      "  -0.81832262 -1.13051016  0.23127935  0.05175125 -1.28311708  0.19201101\n",
      "  -0.6192275  -0.94486144 -0.32131092  0.7005157   0.18800666 -0.28520703\n",
      "   0.4816535   0.59252458 -0.88104186 -1.33565057 -0.59192813 -0.88294937\n",
      "  -0.55048787  0.01340672 -0.94215042 -0.76690406 -1.19608675 -0.16261776]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with L2 Regularization (Ridge)\n",
    "model_l2 = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "model_l2.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_l2 = model_l2.predict(X_test)\n",
    "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "\n",
    "# Print model accuracy and coefficients\n",
    "print(f\"L2 Regularization (Ridge) Model Accuracy: {accuracy_l2:.4f}\")\n",
    "print(\"Model Coefficients:\", model_l2.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c2aab-814b-4fce-8e8a-144cdc84b211",
   "metadata": {},
   "source": [
    "4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d363f5f-d02f-41f0-8664-1c98baee412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regularization Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Elastic Net Regularization\n",
    "model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
    "model_elastic.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_elastic = model_elastic.predict(X_test)\n",
    "accuracy_elastic = accuracy_score(y_test, y_pred_elastic)\n",
    "print(f\"Elastic Net Regularization Model Accuracy: {accuracy_elastic:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cfcc99-a37a-4adb-9896-e3a1d906e975",
   "metadata": {},
   "source": [
    "5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd1f065-ce60-417d-b9ee-bfbb1bf6b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification (One-vs-Rest) Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Logistic Regression for Multiclass classification using OneVsRestClassifier\n",
    "base_model = LogisticRegression(max_iter=1000)\n",
    "model_ovr = OneVsRestClassifier(base_model)\n",
    "model_ovr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_ovr = model_ovr.predict(X_test)\n",
    "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
    "print(f\"Multiclass Classification (One-vs-Rest) Model Accuracy: {accuracy_ovr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d233e2a-7fbe-4256-9ddd-e30f0ceca666",
   "metadata": {},
   "source": [
    "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8cd349-b66f-4dc3-b896-7b76c9796a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Cross-Validation Accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters and Accuracy\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d7659-a763-4c41-81bc-1b12896ba70e",
   "metadata": {},
   "source": [
    "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9971da1d-8a85-4d50-a686-f3a5c68625b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [0.97368421 0.94736842 0.96491228 0.99122807 0.99115044]\n",
      "Average Cross-Validation Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load and prepare the data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_cv = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Cross-validate\n",
    "scores = cross_val_score(model_cv, X_scaled, y, cv=skf, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {scores}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d04468-08c5-46ef-8439-5608beed020d",
   "metadata": {},
   "source": [
    "8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd882e8d-d179-48ca-9a33-0c9fe1c6b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Dataset Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load breast cancer dataset (for simulation of CSV)\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Feature-Target Split\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model_csv = LogisticRegression(max_iter=1000)\n",
    "model_csv.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_csv = model_csv.predict(X_test)\n",
    "accuracy_csv = accuracy_score(y_test, y_pred_csv)\n",
    "print(f\"CSV Dataset Model Accuracy: {accuracy_csv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d29d6-59df-448f-83e8-2af81a5f751a",
   "metadata": {},
   "source": [
    "9. Apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print best parameters and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4459b4ab-7bae-4252-9825-222acd554f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 1}\n",
      "Best Cross-Validation Accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Important Change: max_iter increased to 10000\n",
    "random_search = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=10000),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {random_search.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1dc31-745d-4b92-9789-ac77d353aa8b",
   "metadata": {},
   "source": [
    "10. Implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a2268e3-d3cf-4219-9809-3f4747af0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvO Model Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-vs-One Classifier\n",
    "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
    "ovo_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = ovo_model.predict(X_test)\n",
    "print(f\"OvO Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5e26d-9a33-4b99-b3cf-688b1794eb95",
   "metadata": {},
   "source": [
    "11. Train a Logistic Regression model and visualize the confusion matrix for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e5147b2-efce-4e08-a095-03616377b31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d415f1-5e98-4207-8b0b-521dc457e9ed",
   "metadata": {},
   "source": [
    "12. Train Logistic Regression and evaluate Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8172cab2-2635-447b-86bd-97eed6ef688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9722\n",
      "Recall: 0.9859\n",
      "F1-Score: 0.9790\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0509a5-7e5a-4324-86a9-2802d925ac2b",
   "metadata": {},
   "source": [
    "13. Train on imbalanced data and apply class weights to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebf73a-7eaa-472b-bf0e-adf29f400c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression with class_weight='balanced'\n",
    "model_balanced = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_balanced = model_balanced.predict(X_test)\n",
    "print(f\"Balanced Model Accuracy: {accuracy_score(y_test, y_pred_balanced):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7150a4-753f-4acf-a815-77e1d53383ce",
   "metadata": {},
   "source": [
    "14. Train Logistic Regression on the Titanic dataset, handle missing values, and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bac5c6f-1d37-433c-8849-f085374cc690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Model Accuracy: 0.8042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic = titanic.dropna(subset=['age', 'sex', 'embarked'])\n",
    "\n",
    "# Preprocess\n",
    "X = pd.get_dummies(titanic[['age', 'sex', 'pclass', 'embarked']], drop_first=True)\n",
    "y = titanic['survived']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Titanic Model Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355f07c-d164-43e8-934a-937d17b2303b",
   "metadata": {},
   "source": [
    "15. Apply feature scaling before training Logistic Regression and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e094d575-c35c-40b5-8d59-d10de289a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Scaling: 0.8042\n",
      "Accuracy with Scaling: 0.8042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Without scaling\n",
    "model_no_scaling = LogisticRegression(max_iter=1000)\n",
    "model_no_scaling.fit(X_train, y_train)\n",
    "accuracy_no_scaling = model_no_scaling.score(X_test, y_test)\n",
    "\n",
    "# With scaling (already scaled above)\n",
    "accuracy_with_scaling = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy without Scaling: {accuracy_no_scaling:.4f}\")\n",
    "print(f\"Accuracy with Scaling: {accuracy_with_scaling:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab59a3-bf43-46bf-a0d8-ea1d4a5750a5",
   "metadata": {},
   "source": [
    "16. Evaluate Logistic Regression performance using ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0197e9c7-8dae-48f6-9ed6-b76698245366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.8273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c31467-9033-4a99-918a-bb3010acdb49",
   "metadata": {},
   "source": [
    "17. Train Logistic Regression using a custom learning rate (C=0.5) and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34d84bfc-c0a5-4706-8f86-bf18fc0bac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom C=0.5 Model Accuracy: 0.8042\n"
     ]
    }
   ],
   "source": [
    "model_custom_c = LogisticRegression(C=0.5, max_iter=1000)\n",
    "model_custom_c.fit(X_train, y_train)\n",
    "y_pred_custom_c = model_custom_c.predict(X_test)\n",
    "print(f\"Custom C=0.5 Model Accuracy: {accuracy_score(y_test, y_pred_custom_c):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3498e3-b327-44bd-84ec-d82333bc24e6",
   "metadata": {},
   "source": [
    "18. Identify important features based on model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d630ae5-7157-428f-810e-cd1f59bf3867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "embarked_Q   -0.084305\n",
      "embarked_S   -0.113066\n",
      "age          -0.418824\n",
      "pclass       -1.056420\n",
      "sex_male     -1.245524\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coefficients = pd.Series(model.coef_[0], index=X.columns)\n",
    "print(\"Feature Importances:\")\n",
    "print(coefficients.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5baa8f5-3016-47c5-8e88-a7d349c04dba",
   "metadata": {},
   "source": [
    "19. Evaluate performance using Cohen’s Kappa Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f346343-9507-4737-be78-c88f0b08d4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa Score: 0.5932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec55d8-e7e7-4f7a-89d9-596f22690bfb",
   "metadata": {},
   "source": [
    "20. Visualize Precision-Recall Curve for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7a831-b6b6-4f77-8b68-342d30d29e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91d9b8-7008-4795-b311-a530487de6e3",
   "metadata": {},
   "source": [
    "21. Train Logistic Regression with different solvers and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2daf6323-9369-4d7e-b337-6d7260f6fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: liblinear, Accuracy: 0.8042\n",
      "Solver: saga, Accuracy: 0.8042\n",
      "Solver: lbfgs, Accuracy: 0.8042\n"
     ]
    }
   ],
   "source": [
    "for solver in ['liblinear', 'saga', 'lbfgs']:\n",
    "    model_solver = LogisticRegression(solver=solver, max_iter=1000)\n",
    "    model_solver.fit(X_train, y_train)\n",
    "    score = model_solver.score(X_test, y_test)\n",
    "    print(f\"Solver: {solver}, Accuracy: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8320ab-1a8f-42c0-8efe-c26e6a464117",
   "metadata": {},
   "source": [
    "22. Evaluate performance using Matthews Correlation Coefficient (MCC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "912c3d8c-377c-4ac1-a9d0-d58f178e2170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient: 0.6058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33597fef-1cf3-483f-ad3a-c9ec71f7efa5",
   "metadata": {},
   "source": [
    "23. Compare Logistic Regression on raw and standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcd6893f-e331-4c04-a615-518e46af3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Raw Data: 0.8042\n",
      "Accuracy on Standardized Data: 0.8042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train on raw data\n",
    "model_raw = LogisticRegression(max_iter=1000)\n",
    "model_raw.fit(X_train, y_train)\n",
    "raw_accuracy = model_raw.score(X_test, y_test)\n",
    "\n",
    "# Train on standardized data (already scaled)\n",
    "model_scaled = LogisticRegression(max_iter=1000)\n",
    "model_scaled.fit(X_train, y_train)\n",
    "scaled_accuracy = model_scaled.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy on Raw Data: {raw_accuracy:.4f}\")\n",
    "print(f\"Accuracy on Standardized Data: {scaled_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3218738-2c3a-41dd-9ae1-a5eb62d48e08",
   "metadata": {},
   "source": [
    "24. Find the optimal C (regularization strength) using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be74edb4-ee6a-4334-99eb-5a5d1776519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value: {'C': 0.1}\n",
      "Best Accuracy: 0.7936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best C Value:\", grid_search.best_params_)\n",
    "print(f\"Best Accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946e9c6-029d-47d8-bc53-5b2aa6d755eb",
   "metadata": {},
   "source": [
    "25. Save the trained model using joblib and load it again to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14ef18fa-75fe-4a96-89f8-bbd776fe2fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Accuracy: 0.8042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'logistic_model.pkl')\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load('logistic_model.pkl')\n",
    "\n",
    "# Predict using loaded model\n",
    "loaded_pred = loaded_model.predict(X_test)\n",
    "print(f\"Loaded Model Accuracy: {accuracy_score(y_test, loaded_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
