{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1b74b-2281-4b0a-87cf-e8de2b6a12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Theory questions ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710769ca",
   "metadata": {},
   "source": [
    "### 1. What is a Decision Tree, and how does it work?\n",
    "\n",
    "A Decision Tree is a flowchart-like structure used in machine learning for both classification and regression tasks. It splits the dataset into subsets based on the value of input features. Each internal node represents a decision rule on a feature, each branch represents an outcome of the decision, and each leaf node represents a predicted result. The tree continues to split until a stopping condition is met such as maximum depth, minimum samples per leaf, or no further information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fd083",
   "metadata": {},
   "source": [
    "### 2. What are impurity measures in Decision Trees?\n",
    "\n",
    "Impurity measures quantify the level of disorder or impurity in a dataset at a node. These are used to decide the best feature and threshold to split the data. Common impurity measures include:\n",
    "- **Gini Impurity**: Measures the probability of a wrong classification.\n",
    "- **Entropy**: Measures the level of randomness or disorder.\n",
    "- **Classification Error**: Measures the frequency of the most common label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e819a42",
   "metadata": {},
   "source": [
    "### 3. What is the mathematical formula for Gini Impurity?\n",
    "\n",
    "The formula for Gini Impurity is: **Gini = 1 - Σ(p_i)^2**\n",
    "where p_i is the proportion of class i instances in the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1001e",
   "metadata": {},
   "source": [
    "### 4. What is the mathematical formula for Entropy?\n",
    "\n",
    "The formula for Entropy is: **Entropy = - Σ(p_i * log₂(p_i))**\n",
    "where p_i is the probability of class i in the node. It reaches maximum when all classes are equally likely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5493b6d0",
   "metadata": {},
   "source": [
    "### 5. What is Information Gain, and how is it used in Decision Trees?\n",
    "\n",
    "Information Gain is the decrease in entropy or impurity after a dataset is split on an attribute. It helps the algorithm select the best feature. It is calculated as: **Information Gain = Entropy(parent) - [Weighted average] * Entropy(children)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c364bc",
   "metadata": {},
   "source": [
    "### 6. What is the difference between Gini Impurity and Entropy?\n",
    "\n",
    "Both are measures of impurity used to create splits. Gini is computationally faster and tends to isolate the most frequent class. Entropy comes from information theory and is more sensitive to class distribution changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2466dd",
   "metadata": {},
   "source": [
    "### 7. What is the mathematical explanation behind Decision Trees?\n",
    "\n",
    "Decision Trees use recursive binary partitioning. At each node, the algorithm chooses the feature and threshold that results in the highest Information Gain or lowest Gini Impurity. This is repeated until a stopping criterion is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269ebb5",
   "metadata": {},
   "source": [
    "### 8. What is Pre-Pruning in Decision Trees?\n",
    "\n",
    "Pre-pruning stops the growth of the tree early to avoid overfitting. It uses constraints such as:\n",
    "- Maximum depth\n",
    "- Minimum samples per split\n",
    "- Minimum impurity decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fec55",
   "metadata": {},
   "source": [
    "### 9. What is Post-Pruning in Decision Trees?\n",
    "\n",
    "Post-pruning involves building the full tree and then removing branches that do not provide significant predictive power. This is usually done by validating performance on a separate dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac14bc6",
   "metadata": {},
   "source": [
    "### 10. What is the difference between Pre-Pruning and Post–Pruning?\n",
    "\n",
    "- **Pre-Pruning**: Stops the tree from growing beyond a set condition.\n",
    "- **Post-Pruning**: Builds a complete tree and prunes it back.\n",
    "Pre-pruning can stop useful splits, while post-pruning may recover more generalization by testing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda5adb",
   "metadata": {},
   "source": [
    "### 11. What is a Decision Tree Regressor?\n",
    "\n",
    "A Decision Tree Regressor is a variant of decision trees that predicts continuous numerical values. It splits the data into segments with minimal variance and predicts the mean of the target values in each leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc4a64",
   "metadata": {},
   "source": [
    "### 12. What are the advantages and disadvantages of Decision Trees?\n",
    "\n",
    "**Advantages:**\n",
    "- Easy to understand and interpret\n",
    "- Requires little data preprocessing\n",
    "- Can handle both categorical and numerical data\n",
    "**Disadvantages:**\n",
    "- Prone to overfitting\n",
    "- Can be unstable to small data variations\n",
    "- Biased with imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb39c3",
   "metadata": {},
   "source": [
    "### 13. How does a Decision Tree handle missing values?\n",
    "\n",
    "Some implementations (like C4.5) use surrogate splits or probabilistic approaches. Sklearn generally requires preprocessing like imputing missing values before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c75929",
   "metadata": {},
   "source": [
    "### 14. How does a Decision Tree handle categorical features?\n",
    "\n",
    "Categorical features can be handled by converting them into binary splits or using one-hot encoding. Sklearn requires them to be encoded numerically before model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369f0d5",
   "metadata": {},
   "source": [
    "### 15. What are some real-world applications of Decision Trees?\n",
    "\n",
    "- Credit Risk Assessment\n",
    "- Medical Diagnosis\n",
    "- Fraud Detection\n",
    "- Customer Churn Prediction\n",
    "- Loan Approval\n",
    "- Stock Market Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2498d3-3e17-44fe-b93e-1c492ec76557",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Practical questions ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a064e",
   "metadata": {},
   "source": [
    "### 16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60c7fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813b44b",
   "metadata": {},
   "source": [
    "### 17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3987159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [0.         0.01911002 0.42356658 0.5573234 ]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Feature importances:\", clf.feature_importances_)# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57cb3e4",
   "metadata": {},
   "source": [
    "### 18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2bad6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136efe1",
   "metadata": {},
   "source": [
    "### 19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be365c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5258487964675388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f872b2",
   "metadata": {},
   "source": [
    "### 20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02864beb-6b0b-4abb-bab1-37b74d27de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\91922\\anaconda3\\lib\\site-packages (0.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913191f4-f938-44f9-a846-2f225d616776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Step 2: Train the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Step 3: Export the tree structure to DOT format\n",
    "dot_data = export_graphviz(clf,\n",
    "                           out_file=None,\n",
    "                           feature_names=iris.feature_names,\n",
    "                           class_names=iris.target_names,\n",
    "                           filled=True,\n",
    "                           rounded=True,\n",
    "                           special_characters=True)\n",
    "\n",
    "# Step 4: Render the DOT data using Graphviz\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris_tree\")  # Saves iris_tree.pdf\n",
    "graph.view()  # Opens the file if system supports it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad244b9c",
   "metadata": {},
   "source": [
    "### 21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03245b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full tree accuracy: 1.0\n",
      "Depth-limited tree accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target  # This is categorical (0, 1, 2)\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Full tree (no depth limit)\n",
    "clf_full = DecisionTreeClassifier()\n",
    "clf_full.fit(X_train, y_train)\n",
    "acc_full = accuracy_score(y_test, clf_full.predict(X_test))\n",
    "\n",
    "# Tree with max depth = 3\n",
    "clf_limited = DecisionTreeClassifier(max_depth=3)\n",
    "clf_limited.fit(X_train, y_train)\n",
    "acc_limited = accuracy_score(y_test, clf_limited.predict(X_test))\n",
    "\n",
    "# Compare accuracies\n",
    "print(\"Full tree accuracy:\", acc_full)\n",
    "print(\"Depth-limited tree accuracy:\", acc_limited)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad58f8",
   "metadata": {},
   "source": [
    "### 22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e2ee111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default tree accuracy: 1.0\n",
      "min_samples_split=5 tree accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Default Decision Tree Classifier\n",
    "clf_default = DecisionTreeClassifier()\n",
    "clf_default.fit(X_train, y_train)\n",
    "acc_default = accuracy_score(y_test, clf_default.predict(X_test))\n",
    "\n",
    "# Decision Tree with min_samples_split=5\n",
    "clf_custom = DecisionTreeClassifier(min_samples_split=5)\n",
    "clf_custom.fit(X_train, y_train)\n",
    "acc_custom = accuracy_score(y_test, clf_custom.predict(X_test))\n",
    "\n",
    "# Print and compare accuracies\n",
    "print(\"Default tree accuracy:\", acc_default)\n",
    "print(\"min_samples_split=5 tree accuracy:\", acc_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aeaf48",
   "metadata": {},
   "source": [
    "### 23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "062faa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 1.0\n",
      "Accuracy with scaling   : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. Train without feature scaling\n",
    "clf_unscaled = DecisionTreeClassifier()\n",
    "clf_unscaled.fit(X_train, y_train)\n",
    "acc_unscaled = accuracy_score(y_test, clf_unscaled.predict(X_test))\n",
    "\n",
    "# 2. Apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train with scaled features\n",
    "clf_scaled = DecisionTreeClassifier()\n",
    "clf_scaled.fit(X_train_scaled, y_train)\n",
    "acc_scaled = accuracy_score(y_test, clf_scaled.predict(X_test_scaled))\n",
    "\n",
    "# Print comparison\n",
    "print(\"Accuracy without scaling:\", acc_unscaled)\n",
    "print(\"Accuracy with scaling   :\", acc_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4380b5",
   "metadata": {},
   "source": [
    "### 24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bf10454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using One-vs-Rest Decision Tree: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target  # Multiclass: 0, 1, 2\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train using One-vs-Rest with Decision Tree\n",
    "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier())\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = ovr_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy using One-vs-Rest Decision Tree:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e3f22",
   "metadata": {},
   "source": [
    "### 25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f17c51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances: [0.01911002 0.         0.55727376 0.42361622]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Feature Importances:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0603c3",
   "metadata": {},
   "source": [
    "### 26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "623bef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE full: 0.0\n",
      "MSE limited: 0.0\n"
     ]
    }
   ],
   "source": [
    "reg_full = DecisionTreeRegressor()\n",
    "reg_full.fit(X_train, y_train)\n",
    "\n",
    "reg_limited = DecisionTreeRegressor(max_depth=5)\n",
    "reg_limited.fit(X_train, y_train)\n",
    "\n",
    "print(\"MSE full:\", mean_squared_error(y_test, reg_full.predict(X_test)))\n",
    "print(\"MSE limited:\", mean_squared_error(y_test, reg_limited.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4e5a9",
   "metadata": {},
   "source": [
    "### 27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d15c268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccp_alpha: 0.0000, Accuracy: 1.0\n",
      "ccp_alpha: 0.0092, Accuracy: 1.0\n",
      "ccp_alpha: 0.0127, Accuracy: 1.0\n",
      "ccp_alpha: 0.0185, Accuracy: 1.0\n",
      "ccp_alpha: 0.0397, Accuracy: 1.0\n",
      "ccp_alpha: 0.2503, Accuracy: 0.7111111111111111\n",
      "ccp_alpha: 0.3121, Accuracy: 0.28888888888888886\n"
     ]
    }
   ],
   "source": [
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_pruned = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
    "    clf_pruned.fit(X_train, y_train)\n",
    "    print(f\"ccp_alpha: {ccp_alpha:.4f}, Accuracy: {accuracy_score(y_test, clf_pruned.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e1c35",
   "metadata": {},
   "source": [
    "### 28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08627a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581893a4",
   "metadata": {},
   "source": [
    "### 29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6177f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGwCAYAAACQB97CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0EElEQVR4nO3df3zN9f//8fvZzNnCpo39Un5GGd5rKEbJUmpKvFP04x36LfqBfOq9JHzq7VC9S36nQlLRu/lVvH1QWPLjbYx3P+RHxkpbrLAsjpnz/aNvq+O1zQ7n9XrN2e3q8rpcnNeP5+ux0+l47PF4vl4vh8fj8QgAAMBCQXYHAAAAqh4SEAAAYDkSEAAAYDkSEAAAYDkSEAAAYDkSEAAAYDkSEAAAYDkSEAAAYLlqdgdghrCkR+0OAZXMoU2T7A4BQCUVasG/hP76d+lYVuB8l1EBAQAAlgvICggAAJWKg9/3T0cCAgCA2RwOuyOodEhAAAAwGxUQA94RAABgOSogAACYjRaMAQkIAABmowVjwDsCAAAsRwUEAACz0YIxIAEBAMBstGAMeEcAAIDlqIAAAGA2WjAGJCAAAJiNFowB7wgAALAcFRAAAMxGC8aABAQAALPRgjEgAQEAwGxUQAxIyQAAgOWogAAAYDZaMAYkIAAAmI0ExIB3BAAAWI4KCAAAZgtiEurpSEAAADAbLRgD3hEAAGA5KiAAAJiN+4AYUAEBAMBsjiD/LD7KyMhQ9+7dFR8fL4fDoYULF3qH5XCUurz00ktljjlr1qxSjzl+/LhPsZGAAAAQoAoLC5WYmKhJkyaVuj03N9drmTFjhhwOh3r16lXuuOHh4YZjQ0NDfYqNFgwAAGbzUwvG7XbL7XZ7rXM6nXI6naXun5qaqtTU1DLHi42N9Xq9aNEipaSkqHHjxuXG4XA4DMf6igoIAABm81MLxuVyKSIiwmtxuVx+CfHHH3/UkiVLdP/9959x36NHj6pBgwa66KKLdPPNNysrK8vn81EBAQDAbH6qgKSlpWno0KFe68qqfvjq7bffVq1atXTrrbeWu99ll12mWbNmqVWrViooKNBrr72mjh07atu2bWratGmFz0cCAgDAeaK8dsu5mjFjhu6+++4zzuVo37692rdvX/K6Y8eOat26tSZOnKgJEyZU+HwkIAAAmK2S34jss88+044dOzRv3jyfjw0KCtIVV1yhXbt2+Xacz2cCAAC+cTj8s5jkrbfeUps2bZSYmOjzsR6PR1u3blVcXJxPx1EBAQAgQB09elS7d+8ueZ2dna2tW7cqMjJS9evXlyQVFBToX//6l/75z3+WOkbfvn1Vr169ksmuo0ePVvv27dW0aVMVFBRowoQJ2rp1qyZPnuxTbCQgAACYzaYWTGZmplJSUkpe/z6BtV+/fpo1a5Ykae7cufJ4PLrzzjtLHSMnJ0dBQX/Ef/jwYT300EPKy8tTRESEkpKSlJGRoSuvvNKn2Bwej8fj489T6YUlPWp3CKhkDm0q/SY8ABBqwa/iYTdVfHJmeY4tedwv41QGzAEBAACWowUDAIDZKvlVMHYgAQEAwGwkIAa8IwAAwHJUQAAAMJuJ9/A4X5GAAABgNlowBiQgAACYjQqIASkZAACwHBUQAADMRgvGgAQEAACz0YIxICUDAACWowICAIDJHFRADEhAAAAwGQmIES0YAABgOSogAACYjQKIAQkIAAAmowVjRAsGAABYjgoIAAAmowJiRAICAIDJSECMSEAAADAZCYgRc0DOcx1bN9GH4x/WnuX/0LGsSere+S9e26Mja2n66L9pz/J/6Kd1r2jRpIFqUr+uTdHCLvPef1epXa/VFUmtdMftt2rL5ky7Q4KN+DygMiABOc/VCHPqi537NWTsB6Vu/+DVh9Toojq6ffDran/nWOXk/qyl0x7TBaHVLY4Udln276V6caxLDz70iOZ9uFCtW7fRwIcfVO4PP9gdGmzA58EmDj8tAYQE5Dy3/POvNXrKx1r06TbDtkvqR6vdXxrp8X/M1eavc7Rr3wE94ZqnGmFO9U5tY0O0sMM7b8/UX3v10q233a7GTZroqbThio2L1Qfz3rc7NNiAz4M9HA6HX5ZAYmsC8v3332v48OFKSUlR8+bNlZCQoJSUFA0fPlzfffednaEFBGf136b4HD9xsmTdqVMenSg6qQ6XN7ErLFio6MQJbf/6KyV3uMprfXKHjtq2NcumqGAXPg+oTGxLQNauXavmzZtrwYIFSkxMVN++ffW3v/1NiYmJWrhwoVq0aKHPP//8jOO43W4VFBR4LZ5TxRb8BJXfjr152vfDT3r+sVtUu1aYQqoFa9i91yuuboRi60TYHR4scOjwIRUXFysqKsprfVRUHeXnH7QpKtiFz4N9qIAY2XYVzJAhQ/TAAw/o1VdfLXP74MGDtWnTpnLHcblcGj16tNe64JgrFBJ3pd9iPV+dPHlKdw57U1NH3q3cjJd08mSxPt24Q8vWfmV3aLDY6V9cHo8n4L7MUHF8HqzH+2tkWwXkyy+/1IABA8rc/vDDD+vLL7884zhpaWk6cuSI11IthvkNv8va/p3a3zFWMVcPU6Ouw9Xj0SmKiqihvft/sjs0WODC2hcqODhY+fn5Xut//vknRUXVsSkq2IXPAyoT2xKQuLg4rVu3rszt69evV1xc3BnHcTqdCg8P91ocQcH+DDUgFBw9rvxDR9Wkfl21Tqivj1f/1+6QYIGQ6tXVPKGFNqzzbmduWLdOiZcn2RQV7MLnwT60YIxsa8EMGzZMAwYM0ObNm3X99dcrJiZGDodDeXl5WrFihd58802NHz/ervDOGzXCqqvJxX/c16NhvSj9pVk9HSr4Vd/lHdKt1yXp4KGj+i7vZ7VsGq+X/+c2fbT6v/pkwzc2Rg0r3dPvXg3/+1NKaNlSiYlJSv/XPOXm5ur2PnfYHRpswOfBJoGVO/iFbQnIwIEDFRUVpVdffVWvv/66iot/mzgaHBysNm3aaPbs2erdu7dd4Z03Wic00PI3nyh5/eKwXpKkdxZv0EMj5yi2brjGPXmroqNqKS+/QO9+vFGu6cvsChc2uDG1m44cPqTpU6fo4MEDuqRpM02eNl3x8fXsDg024POAysLh8Xg8dgdRVFRU0pOsU6eOQkJCzmm8sKRH/REWAsihTZPsDgFAJRVqwa/idfrP9cs4+bMCp1JVKZ4FExISUqH5HgAAnI8Cbf6GP1SKBAQAgEBGAmLErdgBAIDlqIAAAGA2CiAGJCAAAJiMFowRLRgAAGA5EhAAAExm151QMzIy1L17d8XHx8vhcGjhwoVe2/v37284R/v27c84bnp6uhISEuR0OpWQkKAFCxb4HBsJCAAAJrMrASksLFRiYqImTSr7Xkg33nijcnNzS5alS5eWO+b69evVp08f3XPPPdq2bZvuuece9e7dWxs3bvQpNuaAAAAQoFJTU5WamlruPk6nU7GxsRUec/z48br++uuVlpYm6beHwq5Zs0bjx4/X+++/X+FxqIAAAGAyf1VA3G63CgoKvBa3231Osa1evVrR0dFq1qyZHnzwQR04cKDc/devX6+uXbt6rbvhhhvKfcBsaUhAAAAwm8M/i8vlUkREhNficrnOOqzU1FS9++67+vTTT/XPf/5TmzZt0rXXXltuUpOXl6eYmBivdTExMcrLy/Pp3LRgAAA4T6SlpWno0KFe65xO51mP16dPn5K/t2zZUm3btlWDBg20ZMkS3XrrrWUed/p8FI/H4/McFRIQAABM5q/7gDidznNKOM4kLi5ODRo00K5du8rcJzY21lDtOHDggKEqcia0YAAAMJldV8H46qefftJ3331X7gNik5OTtWLFCq91y5cvV4cOHXw6FxUQAABMZtedUI8ePardu3eXvM7OztbWrVsVGRmpyMhIjRo1Sr169VJcXJz27t2rZ555RnXq1NFf//rXkmP69u2revXqlcw1eeKJJ9SpUyeNGzdOPXr00KJFi7Ry5UqtXbvWp9hIQAAACFCZmZlKSUkpef37/JF+/fpp6tSp+uKLLzR79mwdPnxYcXFxSklJ0bx581SrVq2SY3JychQU9EfDpEOHDpo7d66effZZjRgxQk2aNNG8efPUrl07n2JzeDwezzn+fJVOWNKjdoeASubQprJvwgOgagu14Ffxix9d5JdxvpvUwy/jVAZUQAAAMBkPozNiEioAALAcFRAAAExGBcSIBAQAAJORgBjRggEAAJajAgIAgMmogBiRgAAAYDbyDwNaMAAAwHJUQAAAMBktGCMSEAAATEYCYkQCAgCAycg/jJgDAgAALEcFBAAAk9GCMSIBAQDAZOQfRrRgAACA5aiAAABgMlowRiQgAACYjPzDiBYMAACwHBUQAABMFhRECeR0JCAAAJiMFowRLRgAAGA5KiAAAJiMq2CMSEAAADAZ+YcRCQgAACajAmLEHBAAAGA5KiAAAJiMCogRCQgAACYj/zCiBQMAACxHBQQAAJPRgjEiAQEAwGTkH0a0YAAAgOWogAAAYDJaMEYkIAAAmIz8w4gWDAAAsBwVEAAATEYLxogEBAAAk5F/GJGAAABgMiogRswBAQAAlgvICsihTZPsDgGVTEfXKrtDQCXyeVqK3SGgirGrAJKRkaGXXnpJmzdvVm5urhYsWKCePXtKkoqKivTss89q6dKl2rNnjyIiInTddddp7Nixio+PL3PMWbNm6d577zWsP3bsmEJDQyscGxUQAABM5nA4/LL4qrCwUImJiZo0yfiL+a+//qotW7ZoxIgR2rJli+bPn6+dO3fqlltuOeO44eHhys3N9Vp8ST6kAK2AAAAAKTU1VampqaVui4iI0IoVK7zWTZw4UVdeeaVycnJUv379Msd1OByKjY09p9iogAAAYDKHwz+L2+1WQUGB1+J2u/0W55EjR+RwOFS7du1y9zt69KgaNGigiy66SDfffLOysrJ8PhcJCAAAJvNXC8blcikiIsJrcblcfonx+PHj+vvf/6677rpL4eHhZe532WWXadasWVq8eLHef/99hYaGqmPHjtq1a5dP56MFAwDAeSItLU1Dhw71Wud0Os953KKiIt1xxx06deqUpkyZUu6+7du3V/v27Uted+zYUa1bt9bEiRM1YcKECp+TBAQAAJP56yoYp9Ppl4Tjz4qKitS7d29lZ2fr008/Lbf6UZqgoCBdccUVPldAaMEAAGAyu66COZPfk49du3Zp5cqVioqK8nkMj8ejrVu3Ki4uzqfjqIAAABCgjh49qt27d5e8zs7O1tatWxUZGan4+Hjddttt2rJliz7++GMVFxcrLy9PkhQZGanq1atLkvr27at69eqVzDUZPXq02rdvr6ZNm6qgoEATJkzQ1q1bNXnyZJ9iIwEBAMBkdt2KPTMzUykpf9x47/f5I/369dOoUaO0ePFiSdLll1/uddyqVavUuXNnSVJOTo6Cgv5omBw+fFgPPfSQ8vLyFBERoaSkJGVkZOjKK6/0KTaHx+PxnMXPVKkdP2l3BKhsuBMq/ow7oeLPQi34VfyaVz/3yzhrhnT0yziVARUQAABMxsPojJiECgAALEcFBAAAk1EAMSIBAQDAZLRgjGjBAAAAy1EBAQDAZBRAjEhAAAAwWRAZiAEtGAAAYDkqIAAAmIwCiBEJCAAAJuMqGCMSEAAATBZE/mHAHBAAAGA5KiAAAJiMFowRCQgAACYj/zCiBQMAACxHBQQAAJM5RAnkdCQgAACYjKtgjGjBAAAAy1EBAQDAZFwFY0QCAgCAycg/jGjBAAAAy1EBAQDAZEGUQAxIQAAAMBn5hxEJCAAAJmMSqhFzQAAAgOWogAAAYDIKIEYkIAAAmIxJqEa0YAAAgOWogAAAYDLqH0YkIAAAmIyrYIxowQAAAMtRAQEAwGRBFEAMSEAAADAZLRijCiUgixcvrvCAt9xyy1kHAwAAqoYKJSA9e/as0GAOh0PFxcXnEg8AAAGHAohRhRKQU6dOmR0HAAABixaMEXNAAAAwGZNQjc4qASksLNSaNWuUk5OjEydOeG17/PHH/RIYAAAIXD7fByQrK0uXXHKJ7rzzTj366KN64YUXNHjwYD3zzDMaP368CSECAHB+czgcfll8lZGRoe7duys+Pl4Oh0MLFy702u7xeDRq1CjFx8crLCxMnTt31ldffXXGcdPT05WQkCCn06mEhAQtWLDA59h8TkCGDBmi7t276+eff1ZYWJg2bNigffv2qU2bNnr55Zd9DgAAgEDn8NPiq8LCQiUmJmrSpEmlbn/xxRf1yiuvaNKkSdq0aZNiY2N1/fXX65dffilzzPXr16tPnz665557tG3bNt1zzz3q3bu3Nm7c6FNsDo/H4/HlgNq1a2vjxo269NJLVbt2ba1fv17NmzfXxo0b1a9fP33zzTc+BWCG4yftjgCVTUfXKrtDQCXyeVqK3SGgEgm1YDbkfXO/8Ms4U//aTG6322ud0+mU0+k847EOh0MLFiwoubLV4/EoPj5egwcP1tNPPy1JcrvdiomJ0bhx4/Twww+XOk6fPn1UUFCgf//73yXrbrzxRl144YV6//33K/yz+FwBCQkJKSkDxcTEKCcnR5IUERFR8ncAAPCHIIfDL4vL5VJERITX4nK5ziqm7Oxs5eXlqWvXriXrnE6nrrnmGq1bt67M49avX+91jCTdcMMN5R5TGp/zvqSkJGVmZqpZs2ZKSUnRc889p/z8fL3zzjtq1aqVr8MBABDw/HUVblpamoYOHeq1riLVj9Lk5eVJ+q2Y8GcxMTHat29fuceVdszv41WUzxWQMWPGKC4uTpL0/PPPKyoqSo888ogOHDig6dOn+zocAACoIKfTqfDwcK/lbBOQ350+udXj8ZxxwuvZHHM6nysgbdu2Lfl73bp1tXTpUl+HAACgSqmMNyKLjY2V9FtF4/fCgiQdOHDAUOE4/bjTqx1nOqY0PldAAACAbxwO/yz+1KhRI8XGxmrFihUl606cOKE1a9aoQ4cOZR6XnJzsdYwkLV++vNxjSuNzBaRRo0blZnJ79uzxdUiYYN7772rWzLeUf/CgmlzSVE/9/Rm1btP2zAfivJZUP0J9k+ureVwt1a3l1JMffKHVO/JLtj/UqaFuaBGtmPBQFRWf0vbcXzRlVba+/KHAxqhhNb4fqo6jR49q9+7dJa+zs7O1detWRUZGqn79+ho8eLDGjBmjpk2bqmnTphozZowuuOAC3XXXXSXH9O3bV/Xq1SuZ7PrEE0+oU6dOGjdunHr06KFFixZp5cqVWrt2rU+x+ZyADB482Ot1UVGRsrKytGzZMv3P//yPr8PBBMv+vVQvjnVp+IiRujyptT78YK4GPvygFixeorj4eLvDg4nCQoK188ejWrwtVy/fbpwUnvPzrxq3bJf2HzomZ0iQ7m53sSbfnagekzfo8K9FNkQMq/H9YI8gm1owmZmZSkn547Lz3yew9uvXT7NmzdJTTz2lY8eOaeDAgTp06JDatWun5cuXq1atWiXH5OTkKCjoj4ZJhw4dNHfuXD377LMaMWKEmjRponnz5qldu3Y+xebzfUDKMnnyZGVmZmrmzJn+GO6cVPX7gNx9x+1qnpCgZ58bXbKuZ/dUpVx7nZ4Y8qSNkdmnKt4HZPOIFEMF5HQ1qgcr4+lOGvDOVm3ae8jC6OxVle8DwveDkRX3ARk4/2u/jDPl1gS/jFMZ+G0OSGpqqtLT0/01HM5S0YkT2v71V0rucJXX+uQOHbVta5ZNUaEyqhbk0K2t4/XL8SLt+vGo3eHAAnw/2MeuW7FXZn7L+z788ENFRkb6azhJ0nfffaeRI0dqxowZZe7jdrsNd4XzBFfsrnCB6NDhQyouLlZUVJTX+qioOsrPP2hTVKhMrm4apTG3Jig0JFj5v5zQwDnbdPgY7ZeqgO8HVCZndSOyP2dhHo9HeXl5OnjwoKZMmeLX4H7++We9/fbb5SYgLpdLo0eP9lo3fMRIPfvcKL/Gcr7xxzXaCEyb9h7SndMzVfuCEP01KU5je7VQvxmbdYg5IFUG3w/W45JTI58TkB49enh9UIOCglS3bl117txZl112mU9jLV68uNztFbmiprS7wnmCq2b1Q5IurH2hgoODlZ/v3ff/+eefFBVVx6aoUJkcLzql7w8d0/eHjunL/QVaMLCdeibFaebnPEoh0PH9YB8SPCOfE5BRo0b57eQ9e/aUw+FQefNgz/QfrbSH8FTlSagh1aureUILbVj3ubpcd33J+g3r1qnztV1sjAyVlcMhhQTz+1lVwPcDKhOfv3WCg4N14MABw/qffvpJwcHBPo0VFxen9PR0nTp1qtRly5YtvoYHSff0u1fz0z/Ugvkfas+33+qlsWOUm5ur2/vcYXdoMFlYSLCaxdRUs5iakqT42qFqFlNTseFOhYYEaVBKY7WsF67YCKcui62pETdfquhwp1ZuN/4/jcDE94M9ghz+WQKJzxWQsqoVbrdb1atX92msNm3aaMuWLSWPBj7dmaojKN2Nqd105PAhTZ86RQcPHtAlTZtp8rTpio+vZ3doMFlCfC1N75tU8vrJrk0lSR9ty9WYJTvVsM4FuvkvLVX7ghAdOVakr34o0AOzsrTn4K92hQyL8f1gj0BLHvyhwvcBmTBhgiRpyJAhev7551WzZs2SbcXFxcrIyNDevXuVlVXxS7k+++wzFRYW6sYbbyx1e2FhoTIzM3XNNddUeEypardgULqqeB8QlK0q3wcERlbcB2To4m/8Ms4rt/g217Iyq/Db/uqrr0r6rQIybdo0r3ZL9erV1bBhQ02bNs2nk1999dXlbq9Ro4bPyQcAAJUNk1CNKpyAZGdnS5JSUlI0f/58XXjhhaYFBQBAIKEFY+Rz4WnVKkrZAADg3Ph8Fcxtt92msWPHGta/9NJLuv322/0SFAAAgcTh8M8SSHxOQNasWaObbrrJsP7GG29URkaGX4ICACCQBDkcflkCic8tmKNHj5Z6uW1ISIgKCgr8EhQAAIGEW/0Z+fyetGzZUvPmzTOsnzt3rhISAucxwQAAwDw+V0BGjBihXr166dtvv9W1114rSfrkk0/03nvv6cMPP/R7gAAAnO8CrHviFz4nILfccosWLlyoMWPG6MMPP1RYWJgSExP16aefKjw83IwYAQA4rwXa/A1/OKv7v910000lE1EPHz6sd999V4MHD9a2bdtUXFzs1wABAEDgOet5MZ9++qn+9re/KT4+XpMmTVK3bt2UmZnpz9gAAAgIXIZr5FMF5Pvvv9esWbM0Y8YMFRYWqnfv3ioqKlJ6ejoTUAEAKAN3QjWqcAWkW7duSkhI0Ndff62JEyfqhx9+0MSJE82MDQAABKgKV0CWL1+uxx9/XI888oiaNm1qZkwAAAQUJqEaVbgC8tlnn+mXX35R27Zt1a5dO02aNEkHDx40MzYAAAICc0CMKpyAJCcn64033lBubq4efvhhzZ07V/Xq1dOpU6e0YsUK/fLLL2bGCQAAAojPV8FccMEFuu+++7R27Vp98cUXevLJJzV27FhFR0frlltuMSNGAADOa0EO/yyB5JxuT3/ppZfqxRdf1Pfff6/333/fXzEBABBQHH76E0jO6kZkpwsODlbPnj3Vs2dPfwwHAEBACbTqhT/wgD4AAGA5v1RAAABA2aiAGJGAAABgMkegXUPrB7RgAACA5aiAAABgMlowRiQgAACYjA6MES0YAABgOSogAACYjIfRGZGAAABgMuaAGNGCAQAAliMBAQDAZA6HfxZfNGzYUA6Hw7AMGjSo1P1Xr15d6v7ffPONH94BI1owAACYLMiGB8lt2rRJxcXFJa+//PJLXX/99br99tvLPW7Hjh0KDw8veV23bl1T4iMBAQDAZHbMQT09cRg7dqyaNGmia665ptzjoqOjVbt2bRMj+w0tGAAAzhNut1sFBQVei9vtPuNxJ06c0Jw5c3Tfffed8bbwSUlJiouLU5cuXbRq1Sp/hW5AAgIAgMmCHP5ZXC6XIiIivBaXy3XG8y9cuFCHDx9W//79y9wnLi5O06dPV3p6uubPn69LL71UXbp0UUZGhh/fiT84PB6Px5SRbXT8pN0RoLLp6DIvi8f55/O0FLtDQCUSasFkhOkb9vllnH5JsYaKh9PplNPpLPe4G264QdWrV9dHH33k0/m6d+8uh8OhxYsX+xzrmTAHBACA80RFko3T7du3TytXrtT8+fN9Pl/79u01Z84cn4+rCBIQAABMZueNUGfOnKno6GjddNNNPh+blZWluLg4E6IiAQEAwHR23Yr91KlTmjlzpvr166dq1bz/yU9LS9P+/fs1e/ZsSdL48ePVsGFDtWjRomTSanp6utLT002JjQQEAIAAtXLlSuXk5Oi+++4zbMvNzVVOTk7J6xMnTmjYsGHav3+/wsLC1KJFCy1ZskTdunUzJTYmoaJKYBIq/oxJqPgzKyahztiUc+adKuC+K+r7ZZzKgAoIAAAm454XRrwnAADAclRAAAAw2ZnuPloVkYAAAGAy0g8jEhAAAExm12W4lRlzQAAAgOWogAAAYDLqH0YkIAAAmIwOjBEtGAAAYDkqIAAAmIzLcI1IQAAAMBntBiPeEwAAYDkqIAAAmIwWjBEJCAAAJiP9MKIFAwAALEcFBAAAk9GCMSIBQZXweVqK3SGgEunoWmV3CKhENo8w//uBdoMRCQgAACajAmJEUgYAACxHBQQAAJNR/zAiAQEAwGR0YIxowQAAAMtRAQEAwGRBNGEMSEAAADAZLRgjWjAAAMByVEAAADCZgxaMAQkIAAAmowVjRAsGAABYjgoIAAAm4yoYIxIQAABMRgvGiAQEAACTkYAYMQcEAABYjgoIAAAm4zJcIxIQAABMFkT+YUALBgAAWI4KCAAAJqMFY0QCAgCAybgKxogWDAAAsBwJCAAAJnP46Y8vRo0aJYfD4bXExsaWe8yaNWvUpk0bhYaGqnHjxpo2bdq5/NjlogUDAIDJ7LoKpkWLFlq5cmXJ6+Dg4DL3zc7OVrdu3fTggw9qzpw5+vzzzzVw4EDVrVtXvXr18ntsJCAAAJwn3G633G631zqn0ymn01nq/tWqVTtj1eN306ZNU/369TV+/HhJUvPmzZWZmamXX37ZlASEFgwAACbzVwvG5XIpIiLCa3G5XGWed9euXYqPj1ejRo10xx13aM+ePWXuu379enXt2tVr3Q033KDMzEwVFRX57b34HRUQAABM5q+rYNLS0jR06FCvdWVVP9q1a6fZs2erWbNm+vHHH/XCCy+oQ4cO+uqrrxQVFWXYPy8vTzExMV7rYmJidPLkSeXn5ysuLs4/P8T/RwICAIDJ/DUFpLx2y+lSU1NL/t6qVSslJyerSZMmevvttw1JzO8cp2VKHo+n1PX+QAsGAIAqoEaNGmrVqpV27dpV6vbY2Fjl5eV5rTtw4ICqVatWasXkXJGAAABgsiCHwy/LuXC73dq+fXuZrZTk5GStWLHCa93y5cvVtm1bhYSEnNO5S0MCAgCAyRx+WnwxbNgwrVmzRtnZ2dq4caNuu+02FRQUqF+/fpJ+m0/St2/fkv0HDBigffv2aejQodq+fbtmzJiht956S8OGDTv7H7wczAEBACAAff/997rzzjuVn5+vunXrqn379tqwYYMaNGggScrNzVVOTk7J/o0aNdLSpUs1ZMgQTZ48WfHx8ZowYYIpl+BKksPz+wyTAHL8pN0RAKjMOrpW2R0CKpHNI1JMP8eGbw/7ZZz2TWr7ZZzKgAoIAAAm42m4RswBAQAAlqMCAgCAyUy4jcZ5jwQEAACTkX8Y0YIBAACWowICAIDZKIEYkIAAAGAyroIxIgEBAMBkTEI1Yg4IAACwHBUQAABMRgHEiAQEAACzkYEY0IIBAACWowICAIDJuArGiAQEAACTcRWMES0YAABgOSogAACYjAKIEQkIAABmIwMxoAUDAAAsRwUEAACTcRWMEQkIAAAm4yoYIxIQAABMRv5hxBwQAABgOSogAACYjRKIAQlIgJr3/ruaNfMt5R88qCaXNNVTf39Grdu0tTss2ITPQ9WVVD9CfZPrq3lcLdWt5dSTH3yh1TvyS7Y/1KmhbmgRrZjwUBUVn9L23F80ZVW2vvyhwMaoAw+TUI1owQSgZf9eqhfHuvTgQ49o3ocL1bp1Gw18+EHl/vCD3aHBBnweqrawkGDt/PGoxi3bWer2nJ9/1bhlu9Tn9f/o/re3KPfIcU2+O1G1LwixOFJUNSQgAeidt2fqr7166dbbblfjJk30VNpwxcbF6oN579sdGmzA56FqW/ftz5q6OlurvskvdfuyLw/oP9mHtP/wce05+KteWb5bNUOrqWl0TYsjDWwOh3+WQEICEmCKTpzQ9q+/UnKHq7zWJ3foqG1bs2yKCnbh8wBfVAty6NbW8frleJF2/XjU7nACisNPSyCxfQ7IsWPHtHnzZkVGRiohIcFr2/Hjx/XBBx+ob9++ZR7vdrvldru91nmCnXI6nabEW9kdOnxIxcXFioqK8lofFVVH+fkHbYoKduHzgIq4ummUxtyaoNCQYOX/ckID52zT4WNFdoeFAGdrBWTnzp1q3ry5OnXqpFatWqlz587Kzc0t2X7kyBHde++95Y7hcrkUERHhtbw0zmV26JWe47RancfjMaxD1cHnAeXZtPeQ7pyeqXtnbtG6b3/S2F4tdCFzQPyLEoiBrQnI008/rVatWunAgQPasWOHwsPD1bFjR+Xk5FR4jLS0NB05csRr+Z+n00yMunK7sPaFCg4OVn6+d7/3559/UlRUHZuigl34PKAijhed0veHjunL/QV6/uMdKj7lUc+kOLvDCigOP/0JJLYmIOvWrdOYMWNUp04dXXLJJVq8eLFSU1N19dVXa8+ePRUaw+l0Kjw83Gupqu0XSQqpXl3NE1pow7rPvdZvWLdOiZcn2RQV7MLnAWfD4ZBCgpkiCHPZOgfk2LFjqlbNO4TJkycrKChI11xzjd577z2bIju/3dPvXg3/+1NKaNlSiYlJSv/XPOXm5ur2PnfYHRpswOehagsLCdbFkWElr+Nrh6pZTE0VHCvS4WNFuv+qhlqzM1/5R92qHRai29vWU3S4Uyu3H7Ax6sBDx9PI1gTksssuU2Zmppo3b+61fuLEifJ4PLrllltsiuz8dmNqNx05fEjTp07RwYMHdEnTZpo8bbri4+vZHRpswOehakuIr6Xpff+odj3Ztakk6aNtuRqzZKca1rlAN/+lpWpfEKIjx4r01Q8FemBWlvYc/NWukAMS+YeRw+PxeOw6ucvl0meffaalS5eWun3gwIGaNm2aTp065dO4x0/6IzoAgaqja5XdIaAS2TwixfRz7PzRPwlds5gL/DJOZWBrAmIWEhAA5SEBwZ+RgNjD9vuAAAAQ6ALtChZ/IAEBAMBkTEI14jorAAACkMvl0hVXXKFatWopOjpaPXv21I4dO8o9ZvXq1XI4HIblm2++8Xt8JCAAAJjMjhuhrlmzRoMGDdKGDRu0YsUKnTx5Ul27dlVhYeEZj92xY4dyc3NLlqZNm/p49jOjBQMAgNlsaMEsW7bM6/XMmTMVHR2tzZs3q1OnTuUeGx0drdq1a5sYHRUQAADOG263WwUFBV7L6Q9kLcuRI0ckSZGRkWfcNykpSXFxcerSpYtWrTLnqjESEAAATOavZ8GU9gBWl+vMD2D1eDwaOnSorrrqKrVs2bLM/eLi4jR9+nSlp6dr/vz5uvTSS9WlSxdlZGT48+2QxH1AAFRB3AcEf2bFfUCy84/7ZZz4Wg5DxcPpdJ7xGWiDBg3SkiVLtHbtWl100UU+nbN79+5yOBxavHixz/GWhzkgAACcJyqSbJzuscce0+LFi5WRkeFz8iFJ7du315w5c3w+7kxIQAAAMJkdtwHxeDx67LHHtGDBAq1evVqNGjU6q3GysrIUFxfn5+hIQAAAMJ8NGcigQYP03nvvadGiRapVq5by8vIkSREREQoL++0JyWlpadq/f79mz54tSRo/frwaNmyoFi1a6MSJE5ozZ47S09OVnp7u9/hIQAAAMJkdt2KfOnWqJKlz585e62fOnKn+/ftLknJzc5WTk1Oy7cSJExo2bJj279+vsLAwtWjRQkuWLFG3bt38Hh+TUAFUOUxCxZ9ZMQl1308Vu1T2TBpE+Tb/ozKjAgIAgMl4FowRCQgAACYj/zDiRmQAAMByVEAAADAZLRgjEhAAAExHBnI6WjAAAMByVEAAADAZLRgjEhAAAExG/mFECwYAAFiOCggAACajBWNEAgIAgMnseBZMZUcCAgCA2cg/DJgDAgAALEcFBAAAk1EAMSIBAQDAZExCNaIFAwAALEcFBAAAk3EVjBEJCAAAZiP/MKAFAwAALEcFBAAAk1EAMSIBAQDAZFwFY0QLBgAAWI4KCAAAJuMqGCMSEAAATEYLxogWDAAAsBwJCAAAsBwtGAAATEYLxogEBAAAkzEJ1YgWDAAAsBwVEAAATEYLxogEBAAAk5F/GNGCAQAAlqMCAgCA2SiBGJCAAABgMq6CMaIFAwAALEcFBAAAk3EVjBEJCAAAJiP/MCIBAQDAbGQgBswBAQAggE2ZMkWNGjVSaGio2rRpo88++6zc/desWaM2bdooNDRUjRs31rRp00yJiwQEAACTOfz0x1fz5s3T4MGDNXz4cGVlZenqq69WamqqcnJySt0/Oztb3bp109VXX62srCw988wzevzxx5Wenn6ub4GBw+PxePw+qs2On7Q7AgCVWUfXKrtDQCWyeUSK6efw179LoT5OnGjXrp1at26tqVOnlqxr3ry5evbsKZfLZdj/6aef1uLFi7V9+/aSdQMGDNC2bdu0fv36s467NFRAAAA4T7jdbhUUFHgtbre71H1PnDihzZs3q2vXrl7ru3btqnXr1pV6zPr16w3733DDDcrMzFRRUZF/foj/LyAnofqaIQYit9stl8ultLQ0OZ1Ou8NBJcBn4g9W/MZb2fF5sJa//l0a9YJLo0eP9lo3cuRIjRo1yrBvfn6+iouLFRMT47U+JiZGeXl5pY6fl5dX6v4nT55Ufn6+4uLizu0H+BMqIAHK7XZr9OjRZWbGqHr4TODP+Dycn9LS0nTkyBGvJS0trdxjHKfdhMTj8RjWnWn/0tafK2oFAACcJ5xOZ4UrVnXq1FFwcLCh2nHgwAFDleN3sbGxpe5frVo1RUVFnV3QZaACAgBAAKpevbratGmjFStWeK1fsWKFOnToUOoxycnJhv2XL1+utm3bKiQkxK/xkYAAABCghg4dqjfffFMzZszQ9u3bNWTIEOXk5GjAgAGSfmvp9O3bt2T/AQMGaN++fRo6dKi2b9+uGTNm6K233tKwYcP8HhstmADldDo1cuRIJpehBJ8J/Bmfh6qhT58++umnn/S///u/ys3NVcuWLbV06VI1aNBAkpSbm+t1T5BGjRpp6dKlGjJkiCZPnqz4+HhNmDBBvXr18ntsAXkfEAAAULnRggEAAJYjAQEAAJYjAQEAAJYjAQEAAJYjAQlQvj5+GYErIyND3bt3V3x8vBwOhxYuXGh3SLCRy+XSFVdcoVq1aik6Olo9e/bUjh077A4LVRAJSADy9fHLCGyFhYVKTEzUpEmT7A4FlcCaNWs0aNAgbdiwQStWrNDJkyfVtWtXFRYW2h0aqhguww1Avj5+GVWHw+HQggUL1LNnT7tDQSVx8OBBRUdHa82aNerUqZPd4aAKoQISYM7m8csAqq4jR45IkiIjI22OBFUNCUiAOZvHLwOomjwej4YOHaqrrrpKLVu2tDscVDHcij1A+fr4ZQBVz6OPPqr//ve/Wrt2rd2hoAoiAQkwZ/P4ZQBVz2OPPabFixcrIyNDF110kd3hoAqiBRNgzubxywCqDo/Ho0cffVTz58/Xp59+qkaNGtkdEqooKiABaOjQobrnnnvUtm1bJScna/r06V6PX0bVcvToUe3evbvkdXZ2trZu3arIyEjVr1/fxshgh0GDBum9997TokWLVKtWrZJqaUREhMLCwmyODlUJl+EGqClTpujFF18sefzyq6++yiV2VdTq1auVkpJiWN+vXz/NmjXL+oBgq7Lmgs2cOVP9+/e3NhhUaSQgAADAcswBAQAAliMBAQAAliMBAQAAliMBAQAAliMBAQAAliMBAQAAliMBAQAAliMBAQAAliMBAQLQqFGjdPnll5e87t+/v3r27Gl5HHv37pXD4dDWrVstPzeAyo0EBLBQ//795XA45HA4FBISosaNG2vYsGEqLCw09byvvfZahW+7TtIAwAo8jA6w2I033qiZM2eqqKhIn332mR544AEVFhZq6tSpXvsVFRUpJCTEL+eMiIjwyzgA4C9UQACLOZ1OxcbG6uKLL9Zdd92lu+++WwsXLixpm8yYMUONGzeW0+mUx+PRkSNH9NBDDyk6Olrh4eG69tprtW3bNq8xx44dq5iYGNWqVUv333+/jh8/7rX99BbMqVOnNG7cOF1yySVyOp2qX7++/vGPf0hSyePZk5KS5HA41Llz55LjZs6cqebNmys0NFSXXXaZpkyZ4nWe//znP0pKSlJoaKjatm2rrKwsP75zAAIJFRDAZmFhYSoqKpIk7d69Wx988IHS09MVHBwsSbrpppsUGRmppUuXKiIiQq+//rq6dOminTt3KjIyUh988IFGjhypyZMn6+qrr9Y777yjCRMmqHHjxmWeMy0tTW+88YZeffVVXXXVVcrNzdU333wj6bck4sorr9TKlSvVokULVa9eXZL0xhtvaOTIkZo0aZKSkpKUlZWlBx98UDVq1FC/fv1UWFiom2++Wddee63mzJmj7OxsPfHEEya/ewDOWx4AlunXr5+nR48eJa83btzoiYqK8vTu3dszcuRIT0hIiOfAgQMl2z/55BNPeHi45/jx417jNGnSxPP66697PB6PJzk52TNgwACv7e3atfMkJiaWet6CggKP0+n0vPHGG6XGmJ2d7ZHkycrK8lp/8cUXe9577z2vdc8//7wnOTnZ4/F4PK+//ronMjLSU1hYWLJ96tSppY4FALRgAIt9/PHHqlmzpkJDQ5WcnKxOnTpp4sSJkqQGDRqobt26Jftu3rxZR48eVVRUlGrWrFmyZGdn69tvv5Ukbd++XcnJyV7nOP31n23fvl1ut1tdunSpcMwHDx7Ud999p/vvv98rjhdeeMErjsTERF1wwQUVigNA1UYLBrBYSkqKpk6dqpCQEMXHx3tNNK1Ro4bXvqdOnVJcXJxWr15tGKd27dpndf6wsDCfjzl16pSk39ow7dq189r2e6vI4/GcVTwAqiYSEMBiNWrU0CWXXFKhfVu3bq28vDxVq1ZNDRs2LHWf5s2ba8OGDerbt2/Jug0bNpQ5ZtOmTRUWFqZPPvlEDzzwgGH773M+iouLS9bFxMSoXr162rNnj+6+++5Sx01ISNA777yjY8eOlSQ55cUBoGqjBQNUYtddd52Sk5PVs2dP/d///Z/27t2rdevW6dlnn1VmZqYk6YknntCMGTM0Y8YM7dy5UyNHjtRXX31V5pihoaF6+umn9dRTT2n27Nn69ttvtWHDBr311luSpOjoaIWFhWnZsmX68ccfdeTIEUm/3dzM5XLptdde086dO/XFF19o5syZeuWVVyRJd911l4KCgnT//ffr66+/1tKlS/Xyyy+b/A4BOF+RgACVmMPh0NKlS9WpUyfdd999atasme644w7t3btXMTExkqQ+ffroueee09NPP602bdpo3759euSRR8odd8SIEXryySf13HPPqXnz5urTp48OHDggSapWrZomTJig119/XfHx8erRo4ck6YEHHtCbb76pWbNmqVWrVrrmmms0a9askst2a9asqY8++khff/21kpKSNHz4cI0bN87EdwfA+czhoXELAAAsRgUEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABYjgQEAABY7v8BVyfnE6HpAmcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97642877",
   "metadata": {},
   "source": [
    "### 30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e526f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Score: 0.9238095238095237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99139244-9f9b-47f8-98d5-09fd17ecc7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
